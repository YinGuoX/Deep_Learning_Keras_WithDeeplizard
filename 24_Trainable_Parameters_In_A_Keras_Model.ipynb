{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "24_Trainable Parameters In A Keras Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJy2dHRPbaGuZqP55f3GoK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Keras_WithDeeplizard/blob/master/24_Trainable_Parameters_In_A_Keras_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqLOvFMcdcNp"
      },
      "source": [
        "# Trainable Parameters In A Keras Model\r\n",
        "在本节中，我们将讨论如何快速访问和计算Keras模型中可学习参数的数量。\r\n",
        "\r\n",
        "## 1.Keras模型示例\r\n",
        "这里，我们有一个非常基本的Keras顺序模型，它由一个有2个输入特征或2个节点的输入层、一个有3个节点的单个隐藏层和一个有2个节点的输出层组成。根据本系列前面的章节，您应该已经熟悉了这种类型的模型。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_xTCYAvXvH9"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "model = Sequential([\r\n",
        "        Dense(3, input_shape=(2,), activation='relu'),\r\n",
        "        Dense(2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY7WsuUqdxWa"
      },
      "source": [
        "例如，在前面，我们使用model.summary()函数检查模型的架构，或者在学习zero-padding时检查每一层的输出形状，但是我们从未讨论过最后一列Param #。这一列向我们展示了每一层中可学习参数的数量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-6kgGQadr3T",
        "outputId": "cd52c54c-0386-4847-d178-a0539785627d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3)                 9         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 8         \n",
            "=================================================================\n",
            "Total params: 17\n",
            "Trainable params: 17\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CmVsFOneByY"
      },
      "source": [
        "在summary()的底部，显示了网络中可学习参数的总数，Keras将其称为可训练参数。\r\n",
        "\r\n",
        "我们已经讨论了什么是[可学习的参数](https://deeplizard.com/learn/video/pg3hJpSopHQ)以及如何计算这些参数的数量在[整个模型的深度学习基础系列](https://deeplizard.com/learn/playlist/PLZbbT5o_s2xq7LwI2y8_QtvuXZedL6tQU),所以去检查,如果你不知道这些东西是什么,然后返回这里。\r\n",
        "\r\n",
        "这个模型实际上是我们在上一集中使用的概念模型的一个精确实现。如果您还记得，在我们的单个隐含层中，我们确实计算出有9个可学习的参数，就像Keras在这个输出中向我们显示的那样。这是来自6个权重和3个偏差。\r\n",
        "\r\n",
        "我们还计算出输出层包含8个由6个权重和2个偏差组成的可学习参数。\r\n",
        "\r\n",
        "现在，回想一下，我们之前也展示了如何通过调用get_weights()函数来访问模型中的权重和偏差，这个函数我们在偏差初始化的视频中讨论过。\r\n",
        "\r\n",
        "通过调用这个函数，我们可以看到我们在每一层中计算的权重和偏差数加起来与我们在model.summary()的参数栏中得到的总数是如何相加的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JE_s5qed38z",
        "outputId": "09f9c2b2-a28b-411b-e6cb-827502828715"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.38624704,  0.85081923,  0.83099425],\n",
              "        [ 0.6841403 ,  0.07812726, -1.0301999 ]], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([[-0.5730672 , -0.488016  ],\n",
              "        [ 0.9243665 ,  0.75059533],\n",
              "        [-0.80555034, -0.75892603]], dtype=float32),\n",
              " array([0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4CczObsfZWD"
      },
      "source": [
        "在这里，我们首先有我们的隐含层的权值，回想一下，这些是在Keras默认使用Xavier或gloot初始化随机初始化的。这里有6个随机数对应我们为这一层计算的6个权重。\r\n",
        "\r\n",
        "然后，我们有我们的3个偏差项，我们之前知道默认情况下，它们被初始化为0。请注意，这两个数字的总和确实是model.summary()输出中为该层提供的9个可学习参数。\r\n",
        "\r\n",
        "我们也可以为输出层做同样的事情。同样，我们有6个随机初始化的权值，我们有2个偏差项初始化为零。将这两个数字相加，我们有8个可学习的参数，再次匹配model.summary()中这一层的输出。\r\n",
        "\r\n",
        "加上8到9，我们总共有17个可学习参数，这与Keras向我们显示的上述输出中可培训参数的总数完全一致。\r\n",
        "\r\n",
        "就是这样了。这就是我们在Keras模型中访问和确认可学习参数总数的方法。接下来，我们将讨论如何使用卷积神经网络来实现这一点，我们将看到在处理cnn时需要考虑的计算中有一些细微的差异，所以请继续关注!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj4kznSWfRVR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}