{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "23_Initializing And Accessing Bias In Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrxih9CHZZC9Twq7Fu7ljG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Keras_WithDeeplizard/blob/master/23_Initializing_And_Accessing_Bias_In_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw2DcQUdVMw4"
      },
      "source": [
        "# Initializing And Accessing Bias In Keras\r\n",
        "在本节课中，我们将看到如何用Keras代码初始化和访问神经网络中的偏差。\r\n",
        "\r\n",
        "## 1.Keras模型\r\n",
        "让我们来看看这个任意的小神经网络，它有一个隐含的密集层，包含4个节点，一个输出层，包含2个节点。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAD5U4tVKZw"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "\r\n",
        "model = Sequential([\r\n",
        "    Dense(4, input_shape=(1,), activation='relu', use_bias=True, bias_initializer='zeros'),\r\n",
        "    Dense(2, activation='softmax')\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOEde8nVeXn"
      },
      "source": [
        "这里的一切都是相当标准的，根据本系列前面的章节，您应该熟悉几乎所有内容。唯一的新项是在隐藏层中，这里有两个我们以前没见过的参数:use_bias和bias_initializer\r\n",
        "\r\n",
        "在另一集中，我们讨论了神经网络中的偏差到底是什么。现在，我们将特别关注在Keras模型中偏差是如何工作的。\r\n",
        "\r\n",
        "## 2.参数：use_bias\r\n",
        "在Keras中，我们用use_bias参数指定我们是否希望一个给定的层包含其所有神经元的偏差。如果我们想要包含偏差，我们可以将参数值设为True。否则，将其设为False。\r\n",
        "\r\n",
        "默认值是True，所以如果我们在这里完全不指定这个参数，该层将默认包含偏差项。\r\n",
        "\r\n",
        "## 3.参数：bias_initializer\r\n",
        "接下来，我们有bias_initializer参数，它决定偏差如何初始化。这个初始化过程和权重初始化过程非常相似我们在另一节课中讲过。\r\n",
        "\r\n",
        "这个参数决定了在我们开始训练模型之前如何首先设置偏差。\r\n",
        "\r\n",
        "我们将此参数的值设置为字符串'zeros'。这意味着在模型开始训练之前，这一层中的所有4个偏差都将被设置为0。\r\n",
        "\r\n",
        "'zeros'实际上是bias_initializer参数的默认值。如果我们想改变这一点，使偏差设置为其他类型的值，比如所有的1或随机数字。\r\n",
        "\r\n",
        "Keras有一个它支持的[初始化列表](https://keras.io/api/layers/initializers/),它们实际上是我们在讨论[权值初始化](https://deeplizard.com/learn/video/8krd5qKVw-Q)时讨论过的相同的初始化列表。如果我们愿意，我们甚至可以用Xavier初始化偏差。\r\n",
        "\r\n",
        "\r\n",
        "## 4.观察初始偏差项\r\n",
        "在我们初始化这些偏差之后，我们可以通过调用model.get_weights来检查它们并查看它们的值。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIraW3uzVake",
        "outputId": "de2e718c-46ef-4ffc-a82c-52be9453e833"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.41759968,  1.0451384 ,  0.2649516 ,  0.9683485 ]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0.], dtype=float32),\n",
              " array([[0.33666253, 0.895895  ],\n",
              "        [0.9848068 , 0.00384641],\n",
              "        [0.11247492, 0.08865929],\n",
              "        [0.3964579 , 0.11553192]], dtype=float32),\n",
              " array([0., 0.], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MfCjyg5W2zc"
      },
      "source": [
        "这就给了我们模型中每一层的所有权重和所有偏差。我们可以看到，我们在第一隐藏层的权值矩阵中有这些随机初始化的权值，我们也有包含4个0的偏差向量，对应于我们指定的“zeros”作为bias_initializer的层中的每个节点的偏差项。\r\n",
        "\r\n",
        "同样，我们有输出层对应的权值矩阵，同样是，后面是该层中每个节点的偏置项对应的包含2个零的偏置向量。\r\n",
        "\r\n",
        "请记住，我们没有为输出层设置任何偏差参数，但是因为Keras使用偏差并默认使用0初始化偏差项，所以我们可以免费获得这些参数。\r\n",
        "\r\n",
        "初始化后，在训练过程中，这些偏差(和权重)将随着模型学习到它们的优化值而更新。如果我们训练这个模型，然后再次调用get_weights()函数，那么权重和偏差的值可能会非常不同。\r\n",
        "\r\n",
        "## 5.最后\r\n",
        "\r\n",
        "正如我们现在所知道的，我们的Keras模型一直在使用偏置，而我们没有做任何改变，因为默认情况下，Keras将偏置初始化为0。我们在密集的图层中展示了这一点，但在其他图层类型中也是如此，比如卷积层。\r\n",
        "\r\n",
        "在第一次从基础层面了解了偏置，现在看到了在代码中的应用，你的想法是什么?\r\n",
        "\r\n",
        "下节见!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoZgJ4i3Wq3S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}