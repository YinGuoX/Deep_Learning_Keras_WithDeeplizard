{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_TensorFlow And Keras GPU Support - CUDA GPU Setup.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPH+LVmZkjAumFjp7Eip9ax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YinGuoX/Deep_Learning_Keras_WithDeeplizard/blob/master/2_TensorFlow_And_Keras_GPU_Support_CUDA_GPU_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAF2pu-UIIQx"
      },
      "source": [
        "# TensorFlow And Keras GPU Support - CUDA GPU Setup\r\n",
        "## 1.对于TensorFlow的GPU支持\r\n",
        "TensorFlow代码（包括Keras）将直接地在单个GPU上运行，而无需明确的代码配置。\r\n",
        "\r\n",
        "TensorFlow GPU支持目前可用于支持cuda的卡的Ubuntu和Windows系统。\r\n",
        "\r\n",
        "关于如何让你的TensorFlow代码在GPU上运行，注意那些能够在GPU上运行的操作现在默认是这样做的：如果TensorFlow同时检测到CPU和GPU，那么GPU支持的代码将默认在GPU上运行。\r\n",
        "\r\n",
        "如果您由于某种原因不希望发生这种情况，则可以显式更改要在其上运行代码的设备，我们将在本课程的稍后部分实际运行代码时进行介绍。\r\n",
        "\r\n",
        "现在，让我们讨论如何使我们的系统允许TensorFlow代码在GPU上运行。\r\n",
        "\r\n",
        "## 2. 硬件需求\r\n",
        "唯一的硬件要求是拥有一个具有CUDA计算能力的NVIDIA GPU卡。\r\n",
        "\r\n",
        "在[TensorFlow](https://www.tensorflow.org/install/gpu#hardware_requirements)网站上查看当前受支持的版本。\r\n",
        "\r\n",
        "接下来，根据您是在Windows环境还是Linux环境中运行代码，会有不同的指令。我们将主要深入讨论Windows方面的内容，但首先让我们了解一下Linux。\r\n",
        "\r\n",
        "### 2.1 Linux配置\r\n",
        "为了简化安装和避免库冲突，TensorFlow建议使用支持GPU的TensorFlow Docker镜像，因为该设置只需要安装NVIDIA GPU驱动程序。\r\n",
        "\r\n",
        "TensorFlow有一个[指南](https://www.tensorflow.org/install/docker)，包含了所有相应的步骤来设置这个。\r\n",
        "\r\n",
        "### 2.2 Windows配置\r\n",
        "对于Windows，这个过程更复杂一些，所以我们现在将介绍涉及的所有步骤。\r\n",
        "#### 2.2.1 安装TensorFlow\r\n",
        "第一步是安装TensorFlow。回想一下，我们之前讨论过TensorFlow的安装就像运行命令pip install TensorFlow一样简单，但是我们也讨论过需要检查以确保您满足TensorFlow系统的要求。如果安装了适当版本的Microsoft Visual c++可重新发布程序，则需要满足这些要求之一。\r\n",
        "#### 2.2.2 安装Nvidia 驱动程序\r\n",
        "现在，我们需要安装Nvidia驱动程序。浏览[英伟达](https://www.nvidia.com/Download/index.aspx?lang=en-us)开始下载。你需要知道你的GPU的规格，这样你才能下载相应的驱动程序。如果您不知道这些规范，您可以导航到设备管理器中的显示适配器，以获得您需要的信息。下载后，通过安装向导安装驱动程序\r\n",
        "\r\n",
        "#### 2.2.3 安装Cuda工具包\r\n",
        "现在我们需要安装CUDA工具包。浏览[英伟达](https://developer.nvidia.com/cuda-toolkit-archive)的网站，选择你想下载的版本。\r\n",
        "\r\n",
        "确保检查TensorFlow当前支持的CUDA Toolkit版本。 您可以在[TensorFlow](https://www.tensorflow.org/install/gpu#software_requirements)的网站上找到该信息。\r\n",
        "\r\n",
        "下载完成后，开始安装。注意，如果您的机器上没有安装Microsoft Visual Studio，那么在安装过程中，您可能会收到这条消息\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "No supported version of Visual Studio was found.\r\n",
        "Some components of CUDA Toolkit will not work properly.\r\n",
        "Please install Visual Studio first to get the full functionality\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lWqcq8yLHB-"
      },
      "source": [
        "根据CUDA Toolkit的系统要求，需要Visual Studio。\r\n",
        "\r\n",
        "如果收到此消息，请不要继续进行下一步安装。 相反，请导航到Microsoft的网站以下载并安装Visual Studio社区版。\r\n",
        "\r\n",
        "注意，您只需要基本软件包。 安装期间不需要选择其他工作负载。\r\n",
        "\r\n",
        "安装完成后，重新安装CUDA Toolkit，您将不再收到有关缺少Visual Studio的消息。\r\n",
        "\r\n",
        "#### 2.2.4 安装CuDNN\r\n",
        "现在我们需要安装cuDNN SDK。再次浏览[Nvidia](https://developer.nvidia.com/zh-cn/cudnn)的网站。为了获得下载的权限，你必须首先创建一个免费帐户，并通过一个快速的电子邮件验证。接下来，选择下载与您在上一步中下载的tensorflow支持的CUDA工具包版本相对应的cuDNN版本。\r\n",
        "\r\n",
        "下载完成后，安装过程需要将下载的文件移动到磁盘上CUDA Toolkit安装路径中的适当位置，并验证环境变量。在这里以及相应的视频中讨论了详细的步骤。\r\n",
        "\r\n",
        "## 3. 验证TensorFlow是否检测到GPU\r\n",
        "打开一个Jupyter Notebook或任何你选择的IDE，运行下面的代码行来测试TensorFlow是否在你的机器上找到了GPU。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4jU_XhgLFeT",
        "outputId": "41fedab0-548e-4897-f3fc-34be9e45087e"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "print(\"Num GPU Available: \",len(tf.config.experimental.list_physical_devices('GPU')))\r\n",
        "print(\"Num GPU Available: \",len(tf.config.experimental.list_physical_devices('CPU')))\r\n",
        "print(\"Num GPU Available: \",len(tf.config.experimental.list_physical_devices('TPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPU Available:  1\n",
            "Num GPU Available:  1\n",
            "Num GPU Available:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9xHPZw9MOaQ"
      },
      "source": [
        "如果输出是1，那么TensorFlow已经成功识别你的GPU。如果输出是0，那么它没有。\r\n",
        "\r\n",
        "如果你收到一个0，然后检查控制台，从那里你启动了你的Jupyter Notebook任何消息。如果收到以下错误，请按照cuDNN安装步骤中讨论的方法验证CUDA环境变量，重新启动机器，然后再试一次。\r\n",
        "\r\n",
        "一旦TensorFlow成功检测到你的GPU，这就是你未来的TensorFlow代码在默认GPU上运行所需要的一切"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxuOSholMBLK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}